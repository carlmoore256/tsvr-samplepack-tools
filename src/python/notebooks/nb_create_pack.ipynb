{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_file import read_samples, write_samples, read_concat_samples\n",
    "from signal_processing.features import extract_features\n",
    "from signal_processing.windowing import window_samples\n",
    "from grain_cloud import GrainCloud\n",
    "from audio_clip import AudioClip, clips_from_folder\n",
    "from utils import get_files_of_types\n",
    "import definitions\n",
    "from manage_packs import update_samplepack_db\n",
    "from signal_processing.processors import most_dissimilar_segments, strip_silence, cross_fade_all\n",
    "from signal_processing import processors\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = \"E:/tsvr-samplepack-tools/data/raw/Environments/CitySounds\"\n",
    "directory = \"E:/AudioClips/MyMusic/Gnuit/vox\"\n",
    "files = get_files_of_types(directory, definitions.AUDIO_FILE_TYPES)\n",
    "clips = clips_from_folder(directory, random_subset=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips_cloud = deepcopy(clips)\n",
    "ws = 16384\n",
    "clip = clips_cloud[3]\n",
    "clip.apply_processor(lambda x: most_dissimilar_segments(x,\n",
    "                                                        n_mfcc=5,\n",
    "                                                        window_size=ws,\n",
    "                                                        hop_size=ws,\n",
    "                                                        top_ratio=0.95,\n",
    "                                                        crossfade_ratio=0.1))\n",
    "clip.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = AudioClip.from_file(\"E:/AudioClips/the factory.wav\")\n",
    "ws = 8192\n",
    "clip.apply_processor(lambda x: most_dissimilar_segments(x,\n",
    "                                                        n_mfcc=28,\n",
    "                                                        window_size=ws,\n",
    "                                                        hop_size=ws,\n",
    "                                                        top_ratio=0.05,\n",
    "                                                        crossfade_ratio=0.05))\n",
    "clip.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from signal_processing.processors import strip_silence, cross_fade_all\n",
    "from copy import deepcopy\n",
    "\n",
    "clips_cloud = deepcopy(clips)\n",
    "cloud = GrainCloud(clips_cloud)\n",
    "ws = 16384\n",
    "\n",
    "new_clip = cloud.render(\n",
    "    clip_processors=[lambda x: strip_silence(x, -40, 0), lambda x: most_dissimilar_segments(x,\n",
    "                                                        n_mfcc=5,\n",
    "                                                        window_size=16384,\n",
    "                                                        hop_size=16384,\n",
    "                                                        top_ratio=0.95,\n",
    "                                                        crossfade_ratio=0.1)],\n",
    "    consolidate_processor=lambda x: cross_fade_all(x, 10000)\n",
    ")\n",
    "\n",
    "new_clip.display()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the GrainCloud to the samplepacks root, which also includes metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud.export_as_samplepack(\"City\",\n",
    "            clip_processors=[lambda x: strip_silence(x, -30, 0)],\n",
    "            consolidate_processor=lambda x: cross_fade_all(x, 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_samplepack_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea - sort samples by first component of MFCC to improve the granulation, timbre separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = 16384\n",
    "clip = AudioClip.from_file(\"E:/AudioClips/the factory.wav\")\n",
    "# clip = AudioClip.from_file(\"E:/AudioClips/MyMusic/jazz_w_kali.wav\")\n",
    "clip.apply_processor(lambda x: processors.strip_silence(x, -50, 1000))\n",
    "clip.apply_processor(lambda x: processors.most_dissimilar_segments(x,\n",
    "                                                        n_mfcc=10,\n",
    "                                                        window_size=ws,\n",
    "                                                        hop_size=ws,\n",
    "                                                        top_ratio=0.15,\n",
    "                                                        crossfade_ratio=0.1))\n",
    "clip.apply_processor(lambda x: processors.normalize(x))\n",
    "clip.display()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"E:/AudioClips/MyMusic/Gnuit/wav\"\n",
    "files = get_files_of_types(directory, definitions.AUDIO_FILE_TYPES)\n",
    "clips = clips_from_folder(directory, random_subset=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ws = 16384 * 4\n",
    "ws = 8192*2\n",
    "cloud = GrainCloud(deepcopy([clip]))\n",
    "new_clip = cloud.render(\n",
    "    # clip_processors=[\n",
    "    #     lambda x: processors.strip_silence(x, -30, 0), \n",
    "    #     # lambda x: processors.most_dissimilar_segments(x, 20, ws, ws, 0.5, crossfade_ratio=0.1), \n",
    "    #     processors.normalize\n",
    "    #     ],\n",
    "    master_processors=[\n",
    "        lambda x: processors.most_dissimilar_segments(x, 20, ws, ws, 0.5, crossfade_ratio=0.1), \n",
    "        processors.normalize\n",
    "        ],\n",
    "    consolidate_processor=lambda x: processors.cross_fade_all(x, 1000)\n",
    ")\n",
    "\n",
    "new_clip.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = cloud.audio_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import kmeans_quantize_distances\n",
    "\n",
    "df_features = cloud.audio_features()\n",
    "kmeans_quantize_distances(df_features, 'mfcc', cluster_ratio=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = GrainCloud(cloud.clips[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = cloud.plot_features_3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea - make a series of tones that generate MFCC coefficients that look like a given 3D model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from signal_processing.features import windowed_mfccs\n",
    "import numpy as np\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = []\n",
    "ws = 16384\n",
    "hop = 16384\n",
    "for clip in cloud.clips:\n",
    "    features = windowed_mfccs(clip.samples[0], window_size=ws, hop_size=hop, n_mfcc=10)\n",
    "    for win_num, m in enumerate(features.T):\n",
    "        mfccs = { f'mfcc_{i}': x for i, x in enumerate(m) }\n",
    "        start_sample = win_num * hop\n",
    "        end_sample = start_sample + ws\n",
    "        all_features.append(\n",
    "            {\n",
    "                'title' : clip.info['title'],\n",
    "                'duration' : clip.samples.shape[1],\n",
    "                'start_sample' : start_sample,\n",
    "                'end_sample' : end_sample,\n",
    "                'frac_idx' : (start_sample + (ws // 2)) / clip.samples.shape[1],\n",
    "                **mfccs\n",
    "            }\n",
    "        )\n",
    "\n",
    "df_features = pd.DataFrame(all_features)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_3d(df_features, x='mfcc_0', y='mfcc_1', z='mfcc_2', opacity=0.8, size='frac_idx', color='title')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
