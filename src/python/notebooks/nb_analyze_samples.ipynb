{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_file import read_samples, write_samples, read_concat_samples\n",
    "from signal_processing.features import extract_features\n",
    "from signal_processing.windowing import window_samples\n",
    "from utils import get_files_of_types\n",
    "import definitions\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "import plotly.express as px\n",
    "import os\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_files_of_types(\"E:/tsvr-samplepack-tools/data/raw/Brass\", definitions.AUDIO_FILE_TYPES)\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_audio(samples, title=\"\", rate=definitions.SAMPLE_RATE):\n",
    "    display(Audio(samples, rate=rate))\n",
    "    plt.title(title)\n",
    "    plt.plot(samples)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = []\n",
    "for f in files:\n",
    "    print(f\"loading sample {f}\")\n",
    "    samples = read_samples(f)\n",
    "    features = extract_features(samples)\n",
    "    all_features.append({'file' : f, **features})\n",
    "    # display_audio(samples, f)\n",
    "df_features = pd.DataFrame(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_size = 8192\n",
    "hop_size = 8192\n",
    "\n",
    "all_features = []\n",
    "for f in files[:10]:\n",
    "    print(f\"loading sample {f}\")\n",
    "    samples = read_samples(f)\n",
    "    windowed_samples = window_samples(samples, win_size, hop_size, window_type=\"rectangular\")\n",
    "    for i, win in enumerate(windowed_samples):\n",
    "        win = np.nan_to_num(win)\n",
    "        print(f\"\\textracting features for {f} window {i+1}/{len(windowed_samples)}\")\n",
    "        try:\n",
    "            features = extract_features(win)\n",
    "            all_features.append({'file' : f, 'window' : i, **features})\n",
    "        except Exception as e:\n",
    "            print(f\"failed to extract features for {f} window {i} | {e}\")\n",
    "df_features = pd.DataFrame(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_quantize_distances(df, cluster_by, cluster_ratio=0.3):\n",
    "    new_df = df.copy()\n",
    "    X = np.array([np.asarray(x) for x in df[cluster_by]])\n",
    "    K = int(len(X) * cluster_ratio)\n",
    "    kmeans = KMeans(n_clusters=K, random_state=0).fit(X)\n",
    "    transformed = kmeans.transform(X)\n",
    "    labels = np.argmin(transformed, axis=1)\n",
    "    for idx, label in enumerate(labels):\n",
    "        new_df.loc[idx, 'label'] = label\n",
    "        new_df.loc[idx, 'distance'] = transformed[idx, label]\n",
    "    return new_df\n",
    "\n",
    "df_dists = kmeans_quantize_distances(df_features, 'mfccs', 0.1)\n",
    "# df_dists[df_dists.label == 4].sort_values('distance', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"mfccs\"\n",
    "df_dists = kmeans_quantize_distances(df_features, key, 0.1)\n",
    "\n",
    "key_pos = \"mfccs\"\n",
    "x_idx = 0\n",
    "y_idx = 1\n",
    "z_idx = 2\n",
    "\n",
    "df_fig = df_dists.copy()\n",
    "\n",
    "df_fig['x'] = df_fig[key_pos].apply(lambda x: x[x_idx])\n",
    "df_fig['y'] = df_fig[key_pos].apply(lambda x: x[y_idx])\n",
    "df_fig['z'] = df_fig[key_pos].apply(lambda x: x[z_idx])\n",
    "\n",
    "px.scatter_3d(df_fig, x='x', y='y', z='z', color='label', size=\"rms\", opacity=0.5, hover_data=['file', 'distance'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could do several things\n",
    "- take the n closest to center of each cluster\n",
    "* - within a cluster, find the permutation of distances that is the largest, with a given N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "# make a function to find the most optimal distances between vectors in the same K label\n",
    "def find_optimal_distances(df, key, k):\n",
    "    df_k = df[df.label == k]\n",
    "    distances = []\n",
    "    for i, j in itertools.combinations(range(len(df_k)), 2):\n",
    "        # distances.append(np.linalg.norm(df_k.iloc[i][key] - df_k.iloc[j][key]))\n",
    "        distances.append({'dist' : np.linalg.norm(df_k.iloc[i][key] - df_k.iloc[j][key]),\n",
    "                          'i' : i,\n",
    "                          'j' : j,\n",
    "                          'file_i' : os.path.basename(df_k.iloc[i]['file']),})\n",
    "    return pd.DataFrame(distances).sort_values('dist', ascending=False)\n",
    "\n",
    "def filter_optimal_distances(df, key, k, min_dist, max_dist):\n",
    "    df_k = df[df.label == k]\n",
    "    distances = []\n",
    "    for i, j in itertools.combinations(range(len(df_k)), 2):\n",
    "        dist = np.linalg.norm(df_k.iloc[i][key] - df_k.iloc[j][key])\n",
    "        print(dist)\n",
    "        if dist > min_dist and dist < max_dist:\n",
    "            distances.append({'dist' : dist,\n",
    "                              'i' : i,\n",
    "                              'j' : j,\n",
    "                              'file_i' : os.path.basename(df_k.iloc[i]['file']),})\n",
    "    print(distances)\n",
    "    return pd.DataFrame(distances).sort_values('dist', ascending=False)\n",
    "\n",
    "# df_optimal = find_optimal_distances(df_dists, 'mfccs', 4)\n",
    "# df_optimal\n",
    "\n",
    "\n",
    "df_filtered = filter_optimal_distances(df_dists, 'mfccs', 4, 0.5, 1.5)\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_features.copy()\n",
    "key = \"mfccs\"\n",
    "subset_size = 0.2\n",
    "\n",
    "# Convert list of vectors to numpy array\n",
    "X = np.array([np.asarray(x) for x in df[key]])\n",
    "# X = X[:, :2]\n",
    "K = int(len(X)*subset_size)\n",
    "\n",
    "kmeans = KMeans(n_clusters=K, random_state=0).fit(X)\n",
    "\n",
    "transformed = kmeans.transform(X)\n",
    "labels = np.argmin(transformed, axis=1)\n",
    "\n",
    "sorted_dists = {}\n",
    "\n",
    "for idx, label in enumerate(labels):\n",
    "    if label not in sorted_dists:\n",
    "        sorted_dists[label] = [{'distance' : transformed[idx, label] , 'row' : df.iloc[idx] }]\n",
    "    else:\n",
    "        sorted_dists[label].append({'distance' : transformed[idx, label], 'row' : df.iloc[idx]})\n",
    "\n",
    "for label in range(K):\n",
    "    sorted_dists[label] = sorted(sorted_dists[label], key=lambda x: x['distance'])\n",
    "\n",
    "for label, center in enumerate(kmeans.cluster_centers_):\n",
    "    color = np.random.rand(3,)\n",
    "    plt.scatter(center[0], center[1], color=color, marker='x', alpha=1)\n",
    "\n",
    "    max_dist = sorted_dists[label][-1]['distance']\n",
    "\n",
    "    for sd in sorted_dists[label]:\n",
    "        x = sd['row'][key][0]\n",
    "        y = sd['row'][key][1]\n",
    "        plt.scatter(x, y, color=color, marker='o', alpha = 1-(sd['distance']/max_dist))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bing\n",
    "\n",
    "\n",
    "def kmeans_subselection(df, key, subset_size):\n",
    "    # Convert list of vectors to numpy array\n",
    "    X = np.array([np.asarray(x) for x in df[key]])\n",
    "    # Run kmeans clustering\n",
    "    kmeans = KMeans(n_clusters=int(len(X)*subset_size), random_state=0).fit(X)\n",
    "    # Get the indices of the most dissimilar vectors\n",
    "    indices = np.argpartition(kmeans.transform(X), -int(len(X)*subset_size), axis=0)[-int(len(X)*subset_size):]\n",
    "    # Return the most dissimilar vectors\n",
    "    print(f'LENGTH OF INDICES: {len(indices)} | idx: {indices}')\n",
    "    selected = [df.iloc[i] for i in indices]\n",
    "    return pd.DataFrame([x.to_dict() for x in selected])\n",
    "\n",
    "# chatgpt\n",
    "\n",
    "def select_dissimilar_vectors(vectors, subset_size):\n",
    "    # Convert list of vectors to numpy array\n",
    "    X = np.array(vectors)\n",
    "    # Initialize KMeans clustering algorithm\n",
    "    kmeans = KMeans(n_clusters=int(subset_size*len(vectors)), random_state=0).fit(X)\n",
    "    # Get the cluster labels for each vector\n",
    "    labels = kmeans.predict(X)\n",
    "    # Compute the centroid of each cluster\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    # Compute the distance of each vector to its centroid\n",
    "    distances = [np.linalg.norm(X[i]-centroids[labels[i]]) for i in range(len(vectors))]\n",
    "    # Sort the vectors by their distance to centroid\n",
    "    sorted_vectors = [vector for _, vector in sorted(zip(distances, vectors))]\n",
    "    # Return a subset of the most dissimilar vectors\n",
    "    return sorted_vectors[:int(subset_size*len(vectors))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
