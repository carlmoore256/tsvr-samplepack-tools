{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grain_cloud import GrainCloud\n",
    "from audio_clip import AudioClip, clips_from_folder\n",
    "from utils import get_files_of_types\n",
    "import definitions\n",
    "from signal_processing import processors\n",
    "import plotly.express as px\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"path/to/audio/files\"\n",
    "files = get_files_of_types(directory, definitions.AUDIO_FILE_TYPES)\n",
    "clips = clips_from_folder(directory, random_subset=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ws = 16384 * 4\n",
    "ws = 8192*4\n",
    "cloud = GrainCloud(deepcopy(clips[:]))\n",
    "new_clip = cloud.render(\n",
    "    clip_processors=[\n",
    "        lambda x: processors.strip_silence(x, -30, 0), \n",
    "        processors.normalize\n",
    "        ],\n",
    "    master_processors=[\n",
    "        # lambda x: processors.most_dissimilar_segments(x, 20, ws, ws, 0.1, crossfade_ratio=0.1), \n",
    "        lambda x: processors.sparsify_by_mfccs(x, 300, window_size=ws, hop_size=ws, crossfade_ratio=0.05),\n",
    "        processors.normalize\n",
    "        ],\n",
    "    consolidate_processor=lambda x: processors.cross_fade_all(x, 10)\n",
    ")\n",
    "\n",
    "new_clip.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_clip.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import sparsify_df\n",
    "\n",
    "df_mfccs = cloud.compute_mfccs(16384, 16384, 20)\n",
    "\n",
    "# Get a list of column names with the prefix 'mfcc'\n",
    "mfcc_columns = [col for col in df_mfccs.columns if col.startswith('mfcc')]\n",
    "df_sparse = sparsify_df(df_mfccs, 100, mfcc_columns)\n",
    "df_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_3d(df_mfccs_scaled, x='mfcc_0', y='mfcc_1', z='mfcc_2', opacity=0.8, color='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_3d(df_sparse, x='mfcc_0', y='mfcc_1', z='mfcc_2', opacity=0.8, color='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ws = 16384 * 4\n",
    "ws = 8192*1\n",
    "cloud = GrainCloud(deepcopy(clips[:]))\n",
    "new_clip = cloud.render(\n",
    "    clip_processors=[\n",
    "        lambda x: processors.strip_silence(x, -30, 0), \n",
    "        # lambda x: processors.sparsify_by_mfccs(x, 3, window_size=ws, hop_size=ws, crossfade_ratio=0.1),\n",
    "        # lambda x: processors.most_dissimilar_segments(x, 20, ws, ws, 0.5, crossfade_ratio=0.1), \n",
    "        processors.normalize\n",
    "        ],\n",
    "    master_processors=[\n",
    "        # lambda x: processors.most_dissimilar_segments(x, 20, ws, ws, 0.1, crossfade_ratio=0.1),\n",
    "        lambda x: processors.sparsify_by_mfccs(x, 14, window_size=ws, hop_size=ws, crossfade_ratio=0.1),\n",
    "        processors.normalize\n",
    "        ],\n",
    "    consolidate_processor=lambda x: processors.cross_fade_all(x, 1000)\n",
    ")\n",
    "\n",
    "new_clip.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from signal_processing.features import samples_mfcc_df\n",
    "\n",
    "df_fig = samples_mfcc_df(new_clip.samples, ws, ws, 20)\n",
    "\n",
    "px.scatter_3d(df_fig, x='mfcc_0', y='mfcc_1', z='mfcc_2', opacity=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ws = 16384 * 4\n",
    "ws = 8192*1\n",
    "cloud = GrainCloud(deepcopy(clips[:]))\n",
    "new_clip = cloud.render(\n",
    "    clip_processors=[\n",
    "        lambda x: processors.strip_silence(x, -30, 0), \n",
    "        # lambda x: processors.most_dissimilar_segments(x, 20, ws, ws, 0.5, crossfade_ratio=0.1), \n",
    "        processors.normalize\n",
    "        ],\n",
    "    master_processors=[\n",
    "        lambda x: processors.most_dissimilar_segments(x, 20, ws, ws, 0.03, crossfade_ratio=0.1),\n",
    "        # lambda x: processors.sparsify_by_mfccs(x, 200, window_size=ws, hop_size=ws, crossfade_ratio=0.1),\n",
    "        processors.normalize\n",
    "        ],\n",
    "    consolidate_processor=lambda x: processors.cross_fade_all(x, 1000)\n",
    ")\n",
    "\n",
    "new_clip.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fig = samples_mfcc_df(new_clip.samples, 8192, 8192, 20)\n",
    "\n",
    "px.scatter_3d(df_fig, x='mfcc_0', y='mfcc_1', z='mfcc_2', opacity=0.8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
